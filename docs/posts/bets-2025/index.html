<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Bets 2025 | Prud&#39;s Log</title>
<meta name="keywords" content="AI, technology, future, predictions, bets">
<meta name="description" content="Verifying previous 6 month bets and making new 6-month bets">
<meta name="author" content="Prudhviraj Naidu">
<link rel="canonical" href="https://prudhvirajn.github.io/posts/bets-2025/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.e7df42763d8de318466c4e083e726ef1427564ee027449f8754ebebe290054cc.css" integrity="sha256-599Cdj2N4xhGbE4IPnJu8UJ1ZO4CdEn4dU6&#43;vikAVMw=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://prudhvirajn.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://prudhvirajn.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://prudhvirajn.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://prudhvirajn.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://prudhvirajn.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://prudhvirajn.github.io/posts/bets-2025/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://prudhvirajn.github.io/posts/bets-2025/">
  <meta property="og:site_name" content="Prud&#39;s Log">
  <meta property="og:title" content="Bets 2025">
  <meta property="og:description" content="Verifying previous 6 month bets and making new 6-month bets">
  <meta property="og:locale" content="en-us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2025-01-27T13:54:08-07:00">
    <meta property="article:modified_time" content="2025-01-27T13:54:08-07:00">
    <meta property="article:tag" content="AI">
    <meta property="article:tag" content="Technology">
    <meta property="article:tag" content="Future">
    <meta property="article:tag" content="Predictions">
    <meta property="article:tag" content="Bets">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Bets 2025">
<meta name="twitter:description" content="Verifying previous 6 month bets and making new 6-month bets">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://prudhvirajn.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Bets 2025",
      "item": "https://prudhvirajn.github.io/posts/bets-2025/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Bets 2025",
  "name": "Bets 2025",
  "description": "Verifying previous 6 month bets and making new 6-month bets",
  "keywords": [
    "AI", "technology", "future", "predictions", "bets"
  ],
  "articleBody": "Background In an ongoing series, I am evaluating my previous 6 month bets and writing new 6-month bets. Before, I do so, I must write a brief description of the state of affairs:\nReasoning models were released by OpenAI (o1 and o1-mini) Sonnet 3.6 was released but Claude 3.5 Opus was not released LLAMA 3.x iterations were released were smaller and offered comparable performance as larger models DeepSeek open-sourced it’s reasoning models so we have a good idea about reasoning Evaluating Previous Bets Bet 1: Claude 3.5 Opus will be the LLM frontier model Result: ❌ Lose\nClaude 3.5 Opus was never released. There is a new regime where smaller models are doing similar/better than larger models. Part of this is smaller models are trained much longer than what scaling laws would suggest. Second reason, in my view, is better supervised finetuning data. Thirdly, it’s a new RL regime that allows models to do tasks that require more steps. The second reason suggests possible distillation from larger models to smaller models. The third step is reminiscent of Instruct-GPT which showed a model A outperforming a model B where B was 100x larger than A. This is my view has significantly altered our view of model capabilities as measured by benchmarks.\n(Figure from “Training language models to follow instructions with human feedback” paper, showing win-rate against SFT 175B GPT3)\nBet 2: OpenAI will shift from ChatGPT product to an agent deployment Result: ✅ Win\nOpenAI will shift from ChatGPT product to an agent deployment i.e there will new post-training and/or scaffolding / “unhobling” that OpenAI will showcase in 6 months.\nOpenAI showcased operator \u0026 o1 series. Dario Amodei is now speaking of virtual collaborator.\nBet 3: LLAMA3-400B multimodal release Result: ✅ Win\nIf LLAMA3-400B releases, there will be a end-to-end finetuned multimodal (text/image guaranteed) possibly (text/image/audio) LLAMA3-400B.\nMeta themselves did this except for image generation. I would still consider it a win.\nBet 4: OpenAI multimodal API restrictions Result: ❌ Lose\nOpenAI would not release end-to-end multimodal freely on their API.\nOpenAI released their API freely. In hindsight, my bet 3 and 4 contradictory. If I believed there would a open-source end-to-end multimodal, it would make sense for OpenAI to release their API access and gain market share. Otherwise, potential customers would just use the open-source one.\nNew Bets Bet 1: Useful mobile / laptop / desktop AI assistants are deployed The economic value of small language models has risen since they will be able to do small tasks consistently. Moreover, there are many private tasks which I would not want to give API access to cloud-based AI. It makes sense that Gemini AI or Siri gets a boost and can do tasks like pull up apps and take actions in apps. This might mean that mobile apps would now need to be local AI-friendly to leverage utility.\nVerifiability: Easy, since there will be an announcement\nBet 2: Benchmarks now measure tasks that take any human beings few minutes but have economic value Previously, we saw benchmarks only test very specific intelligence (they can only be solved by expert humans but demonstrate low economic value). Now, there will be benchmarks measuring utility on generic tasks like paper filing or web lookups (tasks that are easy to do for a human but have economic value).\nVerifiability: Easy since there will be new benchmarks\nBet 3: RL Research Developments Following will be written about:\nThere seems to be a RL limit of 8000 steps due to increasing answer lengths There will be system works trying to optimize the generation part of RL traces There will be works suggesting ideas for how to increase exploration in RL-training The effect of SFT data and prompting has in RL training steps New Scaling Law regime: How much compute should one allocate in pre-training vs post-training Verifiability: Medium, there should be papers but this might spread out across multiple works.\nBet 4: Anthropic releases new model / framework for the virtual collaborator Ok I am going to divide this bet into the following scenario:\nPessimistic: They put out a cheap model for collaborating on daily tasks Medium: They release a model that achieves \u003e40% on Frontier Math \u0026 Humanity’s Last Exam Optimistic: They release a truly superhuman creative genius limited to specific domains, that is arguably superhuman on specific reasoning tasks. Like, it can do human equivalent reasoning of few days on specific problems like number theory proofs or physics simulations. Verifiability: Easy\nEnd-date: End of July\n",
  "wordCount" : "750",
  "inLanguage": "en",
  "datePublished": "2025-01-27T13:54:08-07:00",
  "dateModified": "2025-01-27T13:54:08-07:00",
  "author":{
    "@type": "Person",
    "name": "Prudhviraj Naidu"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://prudhvirajn.github.io/posts/bets-2025/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Prud's Log",
    "logo": {
      "@type": "ImageObject",
      "url": "https://prudhvirajn.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    
    document.body.classList.remove('dark');
    
    localStorage.removeItem("pref-theme");
</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://prudhvirajn.github.io/" accesskey="h" title="Prud&#39;s Log (Alt + H)">Prud&#39;s Log</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://prudhvirajn.github.io/" title="Home">
                    <span>Home</span>
                </a>
            </li>
            <li>
                <a href="https://prudhvirajn.github.io/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="https://prudhvirajn.github.io/cv/" title="CV">
                    <span>CV</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      Bets 2025
    </h1>
    <div class="post-meta"><span title='2025-01-27 13:54:08 -0700 -0700'>January 27, 2025</span>&nbsp;·&nbsp;Prudhviraj Naidu

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#background" aria-label="Background">Background</a></li>
                <li>
                    <a href="#evaluating-previous-bets" aria-label="Evaluating Previous Bets">Evaluating Previous Bets</a><ul>
                        
                <li>
                    <a href="#bet-1-claude-35-opus-will-be-the-llm-frontier-model" aria-label="Bet 1: Claude 3.5 Opus will be the LLM frontier model">Bet 1: Claude 3.5 Opus will be the LLM frontier model</a></li>
                <li>
                    <a href="#bet-2-openai-will-shift-from-chatgpt-product-to-an-agent-deployment" aria-label="Bet 2: OpenAI will shift from ChatGPT product to an agent deployment">Bet 2: OpenAI will shift from ChatGPT product to an agent deployment</a></li>
                <li>
                    <a href="#bet-3-llama3-400b-multimodal-release" aria-label="Bet 3: LLAMA3-400B multimodal release">Bet 3: LLAMA3-400B multimodal release</a></li>
                <li>
                    <a href="#bet-4-openai-multimodal-api-restrictions" aria-label="Bet 4: OpenAI multimodal API restrictions">Bet 4: OpenAI multimodal API restrictions</a></li></ul>
                </li>
                <li>
                    <a href="#new-bets" aria-label="New Bets">New Bets</a><ul>
                        
                <li>
                    <a href="#bet-1-useful-mobile--laptop--desktop-ai-assistants-are-deployed" aria-label="Bet 1: Useful mobile / laptop / desktop AI assistants are deployed">Bet 1: Useful mobile / laptop / desktop AI assistants are deployed</a></li>
                <li>
                    <a href="#bet-2-benchmarks-now-measure-tasks-that-take-any-human-beings-few-minutes-but-have-economic-value" aria-label="Bet 2: Benchmarks now measure tasks that take any human beings few minutes but have economic value">Bet 2: Benchmarks now measure tasks that take any human beings few minutes but have economic value</a></li>
                <li>
                    <a href="#bet-3-rl-research-developments" aria-label="Bet 3: RL Research Developments">Bet 3: RL Research Developments</a></li>
                <li>
                    <a href="#bet-4-anthropic-releases-new-model--framework-for-the-virtual-collaborator" aria-label="Bet 4: Anthropic releases new model / framework for the virtual collaborator">Bet 4: Anthropic releases new model / framework for the virtual collaborator</a>
                </li>
            </ul>
            </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="background">Background<a hidden class="anchor" aria-hidden="true" href="#background">#</a></h2>
<p>In an ongoing series, I am evaluating my previous 6 month bets and writing new 6-month bets. Before, I do so, I must write a brief description of the state of affairs:</p>
<ol>
<li>Reasoning models were released by OpenAI (o1 and o1-mini)</li>
<li>Sonnet 3.6 was released but Claude 3.5 Opus was not released</li>
<li>LLAMA 3.x iterations were released were smaller and offered comparable performance as larger models</li>
<li>DeepSeek open-sourced it&rsquo;s reasoning models so we have a good idea about reasoning</li>
</ol>
<h2 id="evaluating-previous-bets">Evaluating Previous Bets<a hidden class="anchor" aria-hidden="true" href="#evaluating-previous-bets">#</a></h2>
<h3 id="bet-1-claude-35-opus-will-be-the-llm-frontier-model">Bet 1: Claude 3.5 Opus will be the LLM frontier model<a hidden class="anchor" aria-hidden="true" href="#bet-1-claude-35-opus-will-be-the-llm-frontier-model">#</a></h3>
<p><strong>Result: ❌ Lose</strong></p>
<p>Claude 3.5 Opus was never released. There is a new regime where smaller models are doing similar/better than larger models. Part of this is smaller models are trained much longer than what scaling laws would suggest. Second reason, in my view, is better supervised finetuning data. Thirdly, it&rsquo;s a new RL regime that allows models to do tasks that require more steps. The second reason suggests possible distillation from larger models to smaller models. The third step is reminiscent of Instruct-GPT which showed a model A outperforming a model B where B was 100x larger than A. This is my view has significantly altered our view of model capabilities as measured by benchmarks.</p>
<p><img alt="Instruct GPT Distribution" loading="lazy" src="/images/instruct_distribution.png"></p>
<blockquote>
<p><em>(Figure from &ldquo;Training language models to follow instructions with human feedback&rdquo; paper, showing win-rate against SFT 175B GPT3)</em></p></blockquote>
<h3 id="bet-2-openai-will-shift-from-chatgpt-product-to-an-agent-deployment">Bet 2: OpenAI will shift from ChatGPT product to an agent deployment<a hidden class="anchor" aria-hidden="true" href="#bet-2-openai-will-shift-from-chatgpt-product-to-an-agent-deployment">#</a></h3>
<p><strong>Result: ✅ Win</strong></p>
<p>OpenAI will shift from ChatGPT product to an agent deployment i.e there will new post-training and/or scaffolding / &ldquo;unhobling&rdquo; that OpenAI will showcase in 6 months.</p>
<p>OpenAI showcased operator &amp; o1 series. Dario Amodei is now speaking of virtual collaborator.</p>
<h3 id="bet-3-llama3-400b-multimodal-release">Bet 3: LLAMA3-400B multimodal release<a hidden class="anchor" aria-hidden="true" href="#bet-3-llama3-400b-multimodal-release">#</a></h3>
<p><strong>Result: ✅ Win</strong></p>
<p>If LLAMA3-400B releases, there will be a end-to-end finetuned multimodal (text/image guaranteed) possibly (text/image/audio) LLAMA3-400B.</p>
<p>Meta themselves did this except for image generation. I would still consider it a win.</p>
<h3 id="bet-4-openai-multimodal-api-restrictions">Bet 4: OpenAI multimodal API restrictions<a hidden class="anchor" aria-hidden="true" href="#bet-4-openai-multimodal-api-restrictions">#</a></h3>
<p><strong>Result: ❌ Lose</strong></p>
<p>OpenAI would not release end-to-end multimodal freely on their API.</p>
<p>OpenAI released their API freely. In hindsight, my bet 3 and 4 contradictory. If I believed there would a open-source end-to-end multimodal, it would make sense for OpenAI to release their API access and gain market share. Otherwise, potential customers would just use the open-source one.</p>
<h2 id="new-bets">New Bets<a hidden class="anchor" aria-hidden="true" href="#new-bets">#</a></h2>
<h3 id="bet-1-useful-mobile--laptop--desktop-ai-assistants-are-deployed">Bet 1: Useful mobile / laptop / desktop AI assistants are deployed<a hidden class="anchor" aria-hidden="true" href="#bet-1-useful-mobile--laptop--desktop-ai-assistants-are-deployed">#</a></h3>
<p>The economic value of small language models has risen since they will be able to do small tasks consistently. Moreover, there are many private tasks which I would not want to give API access to cloud-based AI. It makes sense that Gemini AI or Siri gets a boost and can do tasks like pull up apps and take actions in apps. This might mean that mobile apps would now need to be local AI-friendly to leverage utility.</p>
<p><strong>Verifiability:</strong> Easy, since there will be an announcement</p>
<h3 id="bet-2-benchmarks-now-measure-tasks-that-take-any-human-beings-few-minutes-but-have-economic-value">Bet 2: Benchmarks now measure tasks that take any human beings few minutes but have economic value<a hidden class="anchor" aria-hidden="true" href="#bet-2-benchmarks-now-measure-tasks-that-take-any-human-beings-few-minutes-but-have-economic-value">#</a></h3>
<p>Previously, we saw benchmarks only test very specific intelligence (they can only be solved by expert humans but demonstrate low economic value). Now, there will be benchmarks measuring utility on generic tasks like paper filing or web lookups (tasks that are easy to do for a human but have economic value).</p>
<p><strong>Verifiability:</strong> Easy since there will be new benchmarks</p>
<h3 id="bet-3-rl-research-developments">Bet 3: RL Research Developments<a hidden class="anchor" aria-hidden="true" href="#bet-3-rl-research-developments">#</a></h3>
<p>Following will be written about:</p>
<ol>
<li>There seems to be a RL limit of 8000 steps due to increasing answer lengths</li>
<li>There will be system works trying to optimize the generation part of RL traces</li>
<li>There will be works suggesting ideas for how to increase exploration in RL-training</li>
<li>The effect of SFT data and prompting has in RL training steps</li>
<li>New Scaling Law regime: How much compute should one allocate in pre-training vs post-training</li>
</ol>
<p><strong>Verifiability:</strong> Medium, there should be papers but this might spread out across multiple works.</p>
<h3 id="bet-4-anthropic-releases-new-model--framework-for-the-virtual-collaborator">Bet 4: Anthropic releases new model / framework for the virtual collaborator<a hidden class="anchor" aria-hidden="true" href="#bet-4-anthropic-releases-new-model--framework-for-the-virtual-collaborator">#</a></h3>
<p>Ok I am going to divide this bet into the following scenario:</p>
<ol>
<li><strong>Pessimistic:</strong> They put out a cheap model for collaborating on daily tasks</li>
<li><strong>Medium:</strong> They release a model that achieves &gt;40% on Frontier Math &amp; Humanity&rsquo;s Last Exam</li>
<li><strong>Optimistic:</strong> They release a truly superhuman creative genius limited to specific domains, that is arguably superhuman on specific reasoning tasks. Like, it can do human equivalent reasoning of few days on specific problems like number theory proofs or physics simulations.</li>
</ol>
<p><strong>Verifiability:</strong> Easy</p>
<hr>
<p><strong>End-date:</strong> End of July</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://prudhvirajn.github.io/tags/ai/">AI</a></li>
      <li><a href="https://prudhvirajn.github.io/tags/technology/">Technology</a></li>
      <li><a href="https://prudhvirajn.github.io/tags/future/">Future</a></li>
      <li><a href="https://prudhvirajn.github.io/tags/predictions/">Predictions</a></li>
      <li><a href="https://prudhvirajn.github.io/tags/bets/">Bets</a></li>
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2025 <a href="https://prudhvirajn.github.io/">Prud&#39;s Log</a></span>
    <span> · Inspired by <a href="https://lilianweng.github.io/" rel="noopener noreferrer" target="_blank">Lil'Log</a></span>
    <span> · 
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer></body>

</html>
