[{"content":"Views expressed below are solely mine and do not reflect views of any affliated institution or persons.\n(Left) US officials ask student visa applicants to set social media to public for screening. (Right) During 1971 Bangladesh liberation war, an Indian soldier checks lungi for weapons1.\n\u0026ldquo;left no good deed unpunished, no bad one unrewarded\u0026rdquo; by Walter Map\nThe US administration now requires student visa applicants to set social media profiles to public for screening2. I was shocked that private speech is used to screen who can, or cannot, enter the United States of America.\nIn times of such irrationality, what can we do except laugh at it? Sadly, I can\u0026rsquo;t make someone laugh to save my own hide. Instead, I set out to share my story of why I applied to come to the United States and my time \u0026ldquo;Waiting for a visa\u0026rdquo;3. Through my story, I hope to convey the absurdity we live in.\nHigh School (2014 - 2016) In high school, I made up my mind to go to the United States for undergraduate studies. During my childhood, to the horror of my parents, I came to admire USA as a place of innovation, freedom, and respect for individual dignity. Whenever I would argue for my privacy and individual freedoms, my parents would often quip, \u0026ldquo;You were born in the wrong country, this is India\u0026rdquo;. I did not grow up with private bedrooms. Even the restroom provided no relief from my mother. Thankfully, in high school, I was travelling the entire stretch of Mumbai city every day. It is public areas that provided privacy. Everyone was too busy trying to get somewhere to care about what I was doing.\nDuring one such trip in sweltering summer, I was lazing away in the public AC bus. The bus conductor approached me. \u0026ldquo;Beta, can you help me with my phone?\u0026rdquo;, he asked. I acquiesced since I had nothing better to do. He gave me his phone. \u0026ldquo;The website is not loading. Can you help me with that?\u0026rdquo;, he explained. As soon as I saw the phone screen, I was startled. The bus conductor was trying to load a pornographic website.\nThe government had recently banned porn4. Yet here I was, trying to keep a straight face while helping the bus conductor uncle (a government official) watch porn. My American friends are horrified at this story. \u0026ldquo;Are Indian males just perverts?\u0026rdquo;, I can see written on their faces. But imagine being an Indian male. You grow up in a joint family house with annoying relatives. You have no private room. You share your bed with a family member. Then you are married off to a random stranger. Within a year of marriage, you are drowned in the wailing screams of an infant. The only shred of individual privacy and dignity is on public buses and trains5.\nAround this time, social media entered the daily life of Indians. If America has closeted communists, in India, we have closeted capitalists. After all, \u0026ldquo;profit is a bad word\u0026rdquo;6 as proclaimed by the first Indian prime minister. Social media became the free space of such individuals. It was the space for the marginalized. The queers. The rejects of society. For a while, Indians found a private space.\nIndian revolt of 1857 It was the day of my SAT exam. I was left in a daze after the exam. \u0026ldquo;Will I be able to go to America?\u0026rdquo; lingered on my mind. I exited the examination hall. In front of me, stood Chatrapathi Shivaji Terminus (CST)7, the pride of Mumbai. The birthplace of Indian railways. Nearby, you can find a famous Pav Bhaji8 stall called \u0026ldquo;Cannon\u0026rdquo;. Why would a food stall be called cannon?\nBecause, there was a cannon in front of it. I liked going there for the beverage stall next to it. They served Indian beverages (kala khatta and rose water). Albeit, my parent\u0026rsquo;s sanitary requirements now surpass what the food stall can provide. Nonetheless, I love going there for kala khatta and looking at the grandeur of CST. I did wonder what the canon was for?\nDuring the early days, Mumbai or Bombay used to be a fort. By 1840s-1850s, The British East India Company completed its control of the Indian subcontinent. In 1857, the Indian soldiers of the Company revolted. Prior to the revolt, in January 1857, chapati (Indian bread) was being distributed anonymously amongst the public. An Indian stranger approached a British official\u0026rsquo;s watchman. He gave the watchman chapati and asked the watchman to make four more like them and distribute them further9. The watchman reported the matter to higherups. These occurrences happened all across North India. A similar distribution occured before the 1806 mutiny in Vellore (South India, and where I was born). But the matter was not pursued further. In May 1857, the soldiers revolted and panic spread across the company. Violence and mayhem seized the subcontinent. It was unclear who was in charge. Some wanted the old Mughal emperor back. Other kingdoms allied with the British against the soldiers revolting. The anarchy led to deaths, confusion, and an atmosphere conducive to irrationality. In an incident10, over a hundred British women and children, held as hostages, were slaughtered. Their bodies were dumped in a well.\nCartoon depicting the British lion striking back at the Indian tiger. The Indian tiger is arched over dead women referencing the death of British women and children10.\nTherefore, when two Indians were found mentioning the revolt while strolling in Bombay markets, they were immediately tied to the cannon and executed by cannonball firing11. The very same spot where today thousands enjoy kala khatta (ok maybe just me) and tirade against the government. But in 1857, Indians did not have the luxury of such privacy under the British.\nThe Radio during the Indian national movement During world war 2, the British tightly controlled communications across the country. India was the prized possession of the crown and a key supplier of materials during the war. In 1942, a band of college-age kids started the Congress Radio12 which started broadcasting speeches of Indian freedom fighters. The Congress Radio was an underground radio station run in corners of Bombay. The radio station frequently changed location to avoid detection. This went on for a few months. The British vehemently scoured the city for the wretched source. They eventually captured the organizers and prosecuted them in a secret trial12.\nThe entire country seemed united in a nationalistic fervour while the British cracked down on free speech. They continuously jailed many freedom fighters. Every month, many would commit suicide in jail, unwilling to bear the harsh treatment. By 1946, the Indian navy revolted, panicking the British. The writing was on the wall. The sun had set on the British Empire. What followed was the partition of India. Arbitrary lines drawn on a map by Radcliffe, who had never been to the country. What ensued was a wave of mass murder resulting in the deaths of a million. People who lived with each other their whole lives became bitter enemies. Irrationality had taken over. It did not even spare Gandhi (the father of India). He was assassinated in 1948. During times of such irrationality, my father often chanted, \u0026ldquo;Maari maari bandh karo aur Gandhi ji ko yaad karo\u0026rdquo; (Stop hitting and beating each other and remember Gandhi). Words I find myself recollecting these days.\nEmergency Era (1970s) Staying true to those words, India adopted democracy on January 26th, 1950, ensuring a non-violent transfer of power between governments. I am happy to report this non-violent transfer of power continued over seven decades except for a brief stint in the 1970s.\nAfter the 1971 Bangladesh war, Mrs. Indira Gandhi became the Iron Lady of India. In 1975, Mrs. Gandhi invoked emergency measures citing internal and external security threats. She clamped down on opposition and the free press became censored.\nPolitical cartoon by Abu Abaraham comics against press censorship. In the top right, we can see the government of India mark censoring this cartoon. 13\nPeople were afraid to speak in restaurants, in the streets, or on the telephone14. Police were kidnapping private students from campuses 15. Rahat Indori perfectly captures this madness16.\nBut police kidnapping private citizens was not the zenith of emergency. Mrs Gandhi did the unimaginable. She united the communists and capitalists against her. In 1977, a young college student Sitaram Yechury (the former General Secretary of the Communist Party of India, Marxist) forced Mrs. Gandhi to resign from the chancellorship of Jawaharlal Nehru University (For non-Indians, Mrs. Indira Gandhi is the daughter of the Mr. Jawaharlal Nehru, the first prime minister of India).\nA young Sitaram Yechury charges Mrs. Gandhi and forces her to resign outside her house. Listen to Unfiltered by Samdish podcast for more details15.\nOur current Prime Minister Modi ji was not behind in this regard. He took part in this opposition to the Emergency. The government recently celebrated the 50th anniversary of the emergency as \u0026ldquo;Samvidhan Hatya Diwas\u0026rdquo;. You can see him below in his various avatars as he evaded capture.\n(Left) Modi ji as a dashing young man (Right) Modi ji disguised as a sikh.17\nWaiting for my visa Throughout history, Indians fought continuously for their privacy \u0026amp; freedoms. When the Indian uncles in my building heard I was leaving for the United States, they congratulated me and even gave me money. They told me to enjoy the freedoms in USA and not think of returning to India. They said, and I quote, \u0026ldquo;You are bright; you can lead a good life there. Forget about India and do not listen to your parents if they ask you to return.\u0026rdquo; Back then, I wanted to learn why United States was great and return to India. But hearing this made me sad. Many years later, when I understood elementary economics and why the United States is successful, I realized they were right. Freedom was a core principle of the United States. Freedom in India was a continuous fight against those willing to steal it. But who knows? Maybe those Indian uncles just wanted to get rid of me from the country.\nIronically, I came to the US in 2016 when President Donald Trump was first elected. I do not believe foreigners should interfere in American public debates or politics. But the present issue at hand is one I must raise concern over as it is an administrative policy affecting visa applicants. While, this novel policy may seem innocuous to an American, it greatly endangers Indians. Private social media spaces are the few remaining breathing rooms for Indian people. In India, people bulldoze homes over public tweets18.\nUnfortunately, I am aware that this random blog article, hidden in the corner of GitHub pages will not sway anybody. Some may decry my efforts as cowardly. Others would decry them as foolish, given recent deportations orders. I merely hope to offer comfort to my friends and colleagues. By sharing my story, I pray it brings some comfort to yours. In such times of irrationality, all we can do is share our stories. Maybe you can write a funny story and we can all laugh together.\nShort responses Q: Why do I think this might get me into trouble?\nA: We live in an era where AI-agents can scour through internet and find information. It is a trivial matter for the US executive branch to use such agents to identify people. I have 25-50% expectation, this article will be flagged by end of 2026.\nhttps://x.com/USAndIndia/status/1943913214569308452/photo/1\nQ: Since, this won\u0026rsquo;t sway any public opinion. Why speak out at all?\nA: I enjoy my freedoms due to the sacrifices of those before me. Not speaking out greatly disturbed my sleep. I do not have much in life barring the joy of food and the joy of sleep. Writing this, allows me to sleep well.\nIn fact, recent events make me question whether I should continue to pursue AI mechanistic interpretability which can be used to align AI agents. Thus, causing greater censorship.\nI do not believe in swaying the American public opinion as a foreigner. I believe foreign interference in domestic debate is immoral but also counter-productive.\nQ: What can we do with this article?\nA: Please share this article only as a comforting story. This article does not direct anyone to take any political action nor do I want this article to get caught up in poltical debate. This article is primarily intended for international students. Secondarily for AI.\nQ: If you get into trouble, will you be sad?\nA: I can only thank my forefathers for their struggle so that I can write this article with some shred of human dignity. But, it was America that me realize the power of freedom and speaking the truth.\nIf I do get into trouble, I would be sad but I am grateful for all the love Americans have given me over the years. I face less racism and discrimination here than I did in India. I came here because America was the country that went to the moon. I thank you for showing me how you can just do things19.\nAlas, what can I do but accept that I was born on the other side of the border line.\n\u0026ldquo;Bangladesh a brutal birth\u0026rdquo; by Kishor Parekh (1972)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;Announcement of Expanded Screening and Vetting for Visa Applicants\u0026rdquo; by US Dept of State (June 18th 2025)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nTitle shamelessly copied from \u0026ldquo;Waiting for a visa\u0026rdquo; by Dr. B. R. Ambedkar (1935 or 1936). I hope Ambedkar saheb finds it in his good heart to forgive me.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nIndian govt bans porn circa 2015-16. Even github was banned for a short while\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nI am not saying women have it easier. I am only providing the perspective of an Indian man.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026lsquo;Profit\u0026rsquo; is a dirty word \u0026#160;\u0026#x21a9;\u0026#xfe0e;\nOnce called Victoria Terminus (VT)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nPav is the portugese word for bread. The bread is similar to dinner rolls. Bhaji refers to a vegetable curry. It is a quick dish for workers. See https://en.wikipedia.org/wiki/Pav_bhaji\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;The personal adventures and experiences of a magistrate during the rise, progress, and suppression of the Indian mutiny\u0026rdquo; by Mark Thornhill (1884)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBritish women and children were massacred in the Bibi Ghar incident\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nThis was a practice by the Mughal empire. I am not aware of the extent of this practice. But this was done so that the bodies could not be cremated. In Indian traditions, if the body is not cremated, the soul will endlessly roam the Earth unable to reincarnate.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;The Voice of Freedom: Congress Radio’s Challenge to British Rule\u0026rdquo; by Isabel Huacuja Alonso\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;From India to Britain and back: The cartoonist who fought censors with a smile \u0026quot; by Soutik Biswas\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;Episode 402: Ajay Shah Brings the Dreams of the 20th Century\u0026rdquo; by Amit Varma\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;Unfiltered by Samdish ft. Sitaram Yechury, Secretary-General, CPI(M)\u0026rdquo; (2024)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;Sarkar Chor Hai by Rahat Indori \u0026ldquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;While Congress which imposed Emergency calls PM Modi a ‘fascist’, here is how he fought the real fascists who suspended fundamental rights in their thirst for power\u0026rdquo; by Anurag (June 2025)\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;14 reasons why BMC has taken a bulldozer to Kangana Ranaut’s office in Mumbai\u0026rdquo; by Manasi Phadke \u0026#160;\u0026#x21a9;\u0026#xfe0e;\n\u0026ldquo;you can just do things\u0026rdquo; ~Sam Altman\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://prudhvirajn.github.io/posts/waiting-for-a-visa/","summary":"Short story about me waiting for a visa.","title":"Waiting for a Visa"},{"content":"Warning: First draft, read at your own peril\nBackground Language models are probabilistic models $P_{\\theta}(x)$ where $x$ is a string and $\\theta$ is the model parameters. During gradient descent, we update $\\theta$ and calculate loss (or error function) $L(\\theta)$.\nIn this article, I want to understand how the model changes when we change $\\theta$ at timestep $t+1$ w.r.t the previous timestep $\\theta_t$. This article is partially motivated by Natural Gradients1 and partly because I am driven by nightmares that I am not setting the learning rate correctly! xD\nThese derivations were shown by Andy1. I just want to re-write them for my understanding.\nThe first two terms are zero Let $P_{\\theta}$ refer to the probability measure induced by $\\theta$ on some set of strings $X$.\n$$ \\begin{aligned} D_{KL}(P_{\\theta_t} || P_{\\theta}) \u0026\\approx D_{KL}(P_{\\theta_t} || P_{\\theta}) \\\\ \u0026\\quad + (\\nabla_{\\theta} D_{KL}(P_{\\theta_t} || P_{\\theta}) \\left. \\right|_{\\theta=\\theta_t}) (\\theta - \\theta_t) \\\\ \u0026\\quad + (\\theta - \\theta_t)^{\\top} H(\\theta_t) (\\theta - \\theta_t) \\end{aligned} $$ where H is the Hessian w.r.t $\\theta$.\nThe first term $D_{KL}(P_{\\theta_t} || P_{\\theta_t})$ is $0$ as the probability distributions are the same.\nThe second term is also $0$. This is quite interesting.\n$$ \\begin{aligned} \\nabla_{\\theta} D_{KL}(P_{\\theta_t} || P_{\\theta}) \\left. \\right|_{\\theta=\\theta_t} \u0026= \\nabla_{\\theta}\\ \\mathbb{E}_{x \\sim P_{\\theta_t}} \\left[\\log \\frac{P_{\\theta_t} (x)}{P_{\\theta} (x)} \\right] \\left. \\right|_{\\theta=\\theta_t} \\\\ \\text{ Since the $x$ is drawn from $P_{\\theta_t}$ which does not depend on $\\theta$} \\\\ \u0026= \\mathbb{E}_{x \\sim P_{\\theta_t}} \\nabla_{\\theta}\\ \\left[\\log \\frac{P_{\\theta_t} (x)}{P_{\\theta} (x)} \\right] \\left. \\right|_{\\theta=\\theta_t} \\\\ \u0026= \\mathbb{E}_{x \\sim P_{\\theta_t}} \\nabla_{\\theta}\\ \\left[\\log P_{\\theta_t} (x) - \\log P_{\\theta} (x) \\right] \\left. \\right|_{\\theta=\\theta_t} \\\\ \\text{Since $P_{\\theta_t} (x)$ does not depend on $\\theta$} \\\\ \u0026= \\mathbb{E}_{x \\sim P_{\\theta_t}} \\left[- \\nabla_{\\theta}\\ \\log P_{\\theta} (x) \\right] \\left. \\right|_{\\theta=\\theta_t} \\\\ \u0026= -\\mathbb{E}_{x \\sim P_{\\theta_t}} \\left[\\nabla_{\\theta}\\ \\log P_{\\theta} (x) \\right] \\left. \\right|_{\\theta=\\theta_t} \\\\ \\text{As we are evaluating the gradient at $\\theta=\\theta_t$ } \\\\ \u0026= -\\mathbb{E}_{x \\sim P_{\\theta_t}} \\frac{1}{P_{\\theta_t} (x)} \\nabla_{\\theta}\\ P_{\\theta} (x) \\left. \\right|_{\\theta=\\theta_t}\\\\ \u0026= -\\sum_{x} P_{\\theta_t} (x) \\frac{1}{P_{\\theta_t} (x)} \\nabla_{\\theta}\\ P_{\\theta} (x) \\left. \\right|_{\\theta=\\theta_t}\\\\ \u0026= -\\sum_{x} \\nabla_{\\theta}\\ P_{\\theta} (x) \\left. \\right|_{\\theta=\\theta_t}\\\\ \\text{By the magic of linearity} \\\\ \u0026= -\\nabla_{\\theta}\\ \\sum_{x} P_{\\theta} (x) \\left. \\right|_{\\theta=\\theta_t}\\\\ \u0026= -\\nabla_{\\theta}\\ 1 \\\\ \u0026= 0 \\\\ \\end{aligned} $$ This means $D_{KL}(P_{\\theta_t} || P_{\\theta}) \\approx (\\theta - \\theta_t)^{\\top} H(\\theta_t) (\\theta - \\theta_t)$.\nBounded weight updates bound behaviour Let\u0026rsquo;s ask the question what is the maximum $D_{KL}(P_{\\theta_t} || P_{\\theta})$ given finite weight updates $\\Delta \\theta$.\n$$ \\begin{aligned} D_{KL}(P_{\\theta_t} || P_{\\theta}) \u0026\\approx \\frac{1}{2}(\\Delta \\theta)^{\\top} H(\\theta_t) (\\Delta \\theta) \\\\ \u0026\\le \\frac{1}{2}(\\Delta \\theta)^{\\top} \\lambda_{max}(\\theta_t) I (\\Delta \\theta) \\\\ \u0026\\le \\frac{1}{2}\\lambda_{max}(\\theta_t) (\\Delta \\theta)^{\\top} (\\Delta \\theta) \\\\ \u0026\\le \\frac{1}{2}\\lambda_{max}(\\theta_t) \\| \\Delta \\theta \\|^2_2 \\\\ \\end{aligned} $$ where $\\lambda_{max}(\\theta_t)$ is the largest eigenvalue of $H(\\theta_t)$\nIf we consider a weight update in SGD with l2 regularization:\n$$ \\theta_{t+1} = \\theta_{t} - \\nu_t (g_t + \\gamma \\theta_t) $$ where $\\nu_t$ is the step multiplier (or learning rate at step t) and $\\gamma$ is the weight decay coefficient. Furthermore, let\u0026rsquo;s presume that the gradient norm is clipped to 1 which is a standard practice.\n$$ \\begin{aligned} D_{KL}(P_{\\theta_t} || P_{\\theta_{t+1}}) \u0026\\le \\frac{1}{2}\\lambda_{max}(\\theta_t) \\| \\Delta \\theta \\|^2_2 \\\\ \u0026\\le \\frac{1}{2}\\lambda_{max}(\\theta_t) \\| \\nu_t (g_t + \\gamma \\theta_t) \\|^2_2 \\\\ \u0026\\le \\frac{1}{2}\\lambda_{max}(\\theta_t) \\nu_t^2 \\| (g_t + \\gamma \\theta_t) \\|^2_2 \\\\ \u0026\\le \\frac{1}{2}\\lambda_{max}(\\theta_t) \\nu_t^2 \\left( \\| g_t \\|_2 + \\| \\gamma \\theta_t \\|_2 \\right)^2 \\\\ \u0026\\le \\frac{1}{2}\\lambda_{max}(\\theta_t) \\nu_t^2 \\left( 1 + \\gamma \\| \\theta_t \\|_2 \\right)^2 \\\\ \\end{aligned} $$ We can conclude three things from the bound $D_{KL}(P_{\\theta_t} || P_{\\theta_{t + 1}})$:\nThe eigenvalues of the Hessian influence model behaviour.\nWeight regularization only increases the magnitude of KL-divergence.\nSmaller learning rate limits change in model behaviour in accordance with expectation.\nIt would be interesting to see how problem formulation or model architecture can change the Hessian. This may suggest certain training methodologies more readily change model behaviours.\nIn fine-tuning, practioners use small learning rates. Despite this, the model behaviours seems to change drastically. This maybe because of we measure other metrics rather than KL-divergence but it may also hint that the eigenvalues of the Hessian are large.\nGhorbani et al, 20192 shows the eigenvalues of the Hessian getting larger during training. They demonstrated this for ResNet over image datasets.\nWe could view pre-training through the lens of eigenstructure of the hessian. Pre-training neural networks helps with finetuning. Measure the PSD-ness of the Hessian could serve as an indicator of how much the behaviour could change during fine-tuning (even RL-finetuning).\nFootnotes Andy Jones. \u0026ldquo;Natural gradients\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nBehrooz Ghorbani, Shankar Krishnan, Ying Xiao. ICML 2019. \u0026ldquo;An Investigation into Neural Net Optimization via Hessian Eigenvalue Density\u0026rdquo;\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://prudhvirajn.github.io/posts/taylor-expansion-of-model-behaviour/","summary":"Model behaviour changes maybe dependent on Hessian, Learning Rate and Weight Norms","title":"Taylor expansion of Model Behaviour"},{"content":"Warning: Unedited First draft, read at your own peril\nSisyphus is a mortal condemned by Zeus to push a boulder up a slope. When he reaches the top of the slope, the boulder automatically falls down and he has to start again. Sounds like a nightmare right? A work that is never completed?\nWhen sisyphus is pushing the boulder, he has only one thing on his mind. To push the boulder up. Why should he push the boulder up? Because the gods commanded it. The ultimate reason: The wishes of the divine. So he had reason and he had a goal thus he had meaning in his work. But what about when the boulder reaches the top? Imagine if the boulder never fell back down. Would he still have meaning? How would he find meaning?\nThis is my dilemma when I feel like a project is about to end. I feel hollow inside, I gave everything to a project and yet I am left with a vague feeling. This usually slows me down at the end of my projects. It\u0026rsquo;s a struggle getting the boulder up with the goal in sight. What would I do next? Would ideas for future projects be worth pursuing? My mind wavers.\nUltimately I know I must complete this project to find out the answers of what would I do next. Ultimately I know it\u0026rsquo;s pointless to ponder such questions right now. But a part of me remains afraid that I won\u0026rsquo;t find meaning again.\nYesterday I went to San Diego Botanical Gardens. It wasn\u0026rsquo;t as grand as the ones in Chicago but I got some familiar things. Peepal trees, banana trees and mango ones too. I was reminded of beautiful things outside my work. I had forgotten all about it. No, I just hid in my work from the outside world.\nPeople can give meaning to each other\u0026rsquo;s life too. I know I gave my parents meaning for the first 18 years of my life. In some sense, I still give them meaning cause I am their unfinished work in their eyes. But in another sense, they are free from pushing that boulder. It scares me. I don\u0026rsquo;t want to be the reason for someone\u0026rsquo;s life and I don\u0026rsquo;t want to burden others as being a reason for mine.\nFor some reason today, I was just reminded of this. What do we live for? Well, I still have a boulder to push. Maybe someday after that, I will go visit that garden again. Sit in afternoon, rays floating through the leaves, a breeze passing by, and a cacophony of colours to see. Maybe someday when I visit that garden again, I wonder what will accompany me?\n","permalink":"https://prudhvirajn.github.io/posts/sisyphian-dilemma/","summary":"\u003cp\u003e\u003cem\u003eWarning: Unedited First draft, read at your own peril\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003eSisyphus is a mortal condemned by Zeus to push a boulder up a slope. When he reaches the top of the slope, the boulder automatically falls down and he has to start again. Sounds like a nightmare right? A work that is never completed?\u003c/p\u003e\n\u003cp\u003eWhen sisyphus is pushing the boulder, he has only one thing on his mind. To push the boulder up. Why should he push the boulder up? Because the gods commanded it. The ultimate reason: The wishes of the divine. So he had reason and he had a goal thus he had meaning in his work. But what about when the boulder reaches the top? Imagine if the boulder never fell back down. Would he still have meaning? How would he find meaning?\u003c/p\u003e","title":"Sisyphian Dilemma"},{"content":"Background In an ongoing series, I am evaluating my previous 6 month bets and writing new 6-month bets. Before, I do so, I must write a brief description of the state of affairs:\nReasoning models were released by OpenAI (o1 and o1-mini) Sonnet 3.6 was released but Claude 3.5 Opus was not released LLAMA 3.x iterations were released were smaller and offered comparable performance as larger models DeepSeek open-sourced it\u0026rsquo;s reasoning models so we have a good idea about reasoning Evaluating Previous Bets Bet 1: Claude 3.5 Opus will be the LLM frontier model Result: ❌ Lose\nClaude 3.5 Opus was never released. There is a new regime where smaller models are doing similar/better than larger models. Part of this is smaller models are trained much longer than what scaling laws would suggest. Second reason, in my view, is better supervised finetuning data. Thirdly, it\u0026rsquo;s a new RL regime that allows models to do tasks that require more steps. The second reason suggests possible distillation from larger models to smaller models. The third step is reminiscent of Instruct-GPT which showed a model A outperforming a model B where B was 100x larger than A. This is my view has significantly altered our view of model capabilities as measured by benchmarks.\n(Figure from \u0026ldquo;Training language models to follow instructions with human feedback\u0026rdquo; paper, showing win-rate against SFT 175B GPT3)\nBet 2: OpenAI will shift from ChatGPT product to an agent deployment Result: ✅ Win\nOpenAI will shift from ChatGPT product to an agent deployment i.e there will new post-training and/or scaffolding / \u0026ldquo;unhobling\u0026rdquo; that OpenAI will showcase in 6 months.\nOpenAI showcased operator \u0026amp; o1 series. Dario Amodei is now speaking of virtual collaborator.\nBet 3: LLAMA3-400B multimodal release Result: ✅ Win\nIf LLAMA3-400B releases, there will be a end-to-end finetuned multimodal (text/image guaranteed) possibly (text/image/audio) LLAMA3-400B.\nMeta themselves did this except for image generation. I would still consider it a win.\nBet 4: OpenAI multimodal API restrictions Result: ❌ Lose\nOpenAI would not release end-to-end multimodal freely on their API.\nOpenAI released their API freely. In hindsight, my bet 3 and 4 contradictory. If I believed there would a open-source end-to-end multimodal, it would make sense for OpenAI to release their API access and gain market share. Otherwise, potential customers would just use the open-source one.\nNew Bets Bet 1: Useful mobile / laptop / desktop AI assistants are deployed The economic value of small language models has risen since they will be able to do small tasks consistently. Moreover, there are many private tasks which I would not want to give API access to cloud-based AI. It makes sense that Gemini AI or Siri gets a boost and can do tasks like pull up apps and take actions in apps. This might mean that mobile apps would now need to be local AI-friendly to leverage utility.\nVerifiability: Easy, since there will be an announcement\nBet 2: Benchmarks now measure tasks that take any human beings few minutes but have economic value Previously, we saw benchmarks only test very specific intelligence (they can only be solved by expert humans but demonstrate low economic value). Now, there will be benchmarks measuring utility on generic tasks like paper filing or web lookups (tasks that are easy to do for a human but have economic value).\nVerifiability: Easy since there will be new benchmarks\nBet 3: RL Research Developments Following will be written about:\nThere seems to be a RL limit of 8000 steps due to increasing answer lengths There will be system works trying to optimize the generation part of RL traces There will be works suggesting ideas for how to increase exploration in RL-training The effect of SFT data and prompting has in RL training steps New Scaling Law regime: How much compute should one allocate in pre-training vs post-training Verifiability: Medium, there should be papers but this might spread out across multiple works.\nBet 4: Anthropic releases new model / framework for the virtual collaborator Ok I am going to divide this bet into the following scenario:\nPessimistic: They put out a cheap model for collaborating on daily tasks Medium: They release a model that achieves \u0026gt;40% on Frontier Math \u0026amp; Humanity\u0026rsquo;s Last Exam Optimistic: They release a truly superhuman creative genius limited to specific domains, that is arguably superhuman on specific reasoning tasks. Like, it can do human equivalent reasoning of few days on specific problems like number theory proofs or physics simulations. Verifiability: Easy\nEnd-date: End of July\n","permalink":"https://prudhvirajn.github.io/posts/bets-2025/","summary":"Verifying previous 6 month bets and making new 6-month bets","title":"Bets 2025"},{"content":" Warning: The following blog post has not been proof-read due to the author\u0026rsquo;s commitment to posting and writing.\nSince it\u0026rsquo;s the new year, I had to do my predictions for the next 6 months. But strangely, I am having a hard time. More so, this is probably the first time in my life, I can not imagine a realistic future for me. Weirdly, I am quite confident on how the future of the world might look like (I am not saying it\u0026rsquo;s fixed but I do believe the probabilities are concentrated on few possible trajectories).\nEarly Dreams: The Physics Path When I was a kid, I imagined my life as a physicist doing the following:\nObserve interesting real world phenomenon Try to explain it with general principles Rinse and repeat until I reach few general principles that explains all phenomenon or I die It sounds funny now, but for the first 13 years of my life thats what I wanted to do until I realized I had to take living standards into consideration.\nThe Pragmatic Pivot Then I optimized to maximize living standards and economic freedoms:\nLearns software engineering and economic freedoms from the ideal country to do so (USA) Get a decent software job in a country with high standards of living and respectable economic freedoms Save money to retire to learn and do physics The AI Awakening During my CS bachelors, I was introduced to formal \u0026amp; fuzzy logic. While, it was highly interesting, I didn\u0026rsquo;t consider them real world phenomenons. I continued on with my masters but in the back of my mind I had observed neural networks which I started perceiving as interesting phenomenon. Then there were two key insights:\nScaling Laws: For me this established that learning in neural networks is a predictable phenomenon and not memorization into latent high-dimensional spaces\nDemis Hassabis\u0026rsquo;s quote: \u0026ldquo;Let\u0026rsquo;s solve AI and then use AI to solve everything else.\u0026rdquo;\nSo I switched back to the same route and I am on that route.\nThe Research Cycle: Beauty and Despair Now, I am stuck with an established unexplained phenomenon (of scaling laws) which goes like this:\nGet more data to ensure phenomenon is real Come up with a hypothesis to explain, feel the excitement Test hypothesis which comes up false or unclear, feel the despair Weirdly, maybe I am masochist, but I get more motivated. I think it\u0026rsquo;s because I believe the hypothesis that will explain the phenomenon has to be an amazing simple connection I did not make until now and how amazing it would be to gain a new perspective of neural networks. If it turns out to be because I set some random hyperparameter incorrectly (I checked this one again and again but it\u0026rsquo;s my worst nightmare and anxiety), I am pretty sure I would go into dismay. Either way I guarantee I am going to think I am world\u0026rsquo;s biggest idiot once I see it. Rinse repeat (I am currently on cycle 4). The only progress I have made is getting more data and confirming the phenomenon is replicable and general. The Superintelligence Question But recently I started reading Shane Legg\u0026rsquo;s dissertation on Machine Superintelligence and trying to read up on it. I do think superintelligence should be taken real (My expected belief is it will be real by 2040 but I have high variance regarding its efficacy).\nSo the question is, what will I do in the future?\nSoftware Engineering\u0026rsquo;s Uncertain Future Software engineering? I don\u0026rsquo;t believe there will be new software engineering jobs since experienced developers can make the high intelligent software architecture details and overlook the implementation (the rest of the software is implemented by ai agents). Why would anyone hire new comers?\nThe Future of Research How about doing what I am doing now? I think I am blessed by some benevolent god (certainly blessed by my advisors) who have decided to allow me to do what I am doing now. Literally, for the second time in my life, I thought I breathed air as a free man unencumbered by educational or professional commitments.\nBut realistically, would industry hire researchers? My guess would be companies can now standardize industrial research with ai agents. For AI research, let\u0026rsquo;s break it down in two categories:\nFor empirical research (where in industry the problem is easy to identify and define), AI\u0026rsquo;s can try a large space of simple ideas and drive industrial research for standard products.\nFor theoretical work, AI\u0026rsquo;s can certainly carry out the mechanical work of proving theorems. But it\u0026rsquo;s unclear whether AI\u0026rsquo;s would be able to come up with frameworks or right intuitions of building theory about topics. This is unclear to me, not as a limitation of the AI.\nThe Path Forward: Superintelligence Research So going back, do I believe industry would hire droves of researchers in 2040 as they are doing now to work on AI. My answer is only to work on superintelligence on possible the following problems:\nSafety: How do you define safety and align superintelligence\nTheoretical Underpinnings: For a system that sees all of the internet, we would not be able to rely on empirical observations to certify it\u0026rsquo;s robustness. I do believe that after 2030, we will see (generally accepted) theory of work being built on how learning actually occurs in AI, safety and alignment of AI (not the current empirical works we have now), work on intent / motivations for sustained agents that achieve broad goals rather than specific outcomes.\nConclusion: Beliefs Updated To be honest, when I started this essay, I was feeling quite dismayed about my future employment options. By the end of writing this, I do feel quite satisfied. (Beliefs updated)\n","permalink":"https://prudhvirajn.github.io/posts/the-unknown/","summary":"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eWarning:\u003c/strong\u003e The following blog post has not been proof-read due to the author\u0026rsquo;s commitment to posting and writing.\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eSince it\u0026rsquo;s the new year, I had to do my predictions for the next 6 months. But strangely, I am having a hard time. More so, this is probably the first time in my life, I can not imagine a realistic future for me. Weirdly, I am quite confident on how the future of the world might look like (I am not saying it\u0026rsquo;s fixed but I do believe the probabilities are concentrated on few possible trajectories).\u003c/p\u003e","title":"The Unknown"},{"content":"Background At LEI (Lab for Emerging Intelligence) UC San Diego, we are developing GenAI powered applications at the university. As such, we primarily hire undergraduates to take on such projects. However, the projects involve writing and deploying applications for thousands of users. This requires us to write high quality code that is easy to maintain.\nAs part of these efforts, we are internally running a Code Review Contest to help people read code and understand what is required from them in terms of code style, documentation and quality. Furthermore, the contest helps get reviews out faster so that PRs are not bottlenecked by few.\nRules Every week, everybody must review one PR per week The winner must review at least 2 PR People must review PRs in repository they do not actively contribute code to (for it to count in this contest; the idea is people have to read the issue and related documentation so they understand what documentation needs to be written in their respective repository) For their to be a weekly winner, everybody must review a PR (so that one doesn\u0026rsquo;t hog up reviewing all PRs or in case there are too few PR in a week) This can not distract from assigned work Weekly Pot: $10 If nobody wins, then the money goes into the monthly pot which goes to the person with highest reviews.\nContest runs till end of August.\nWeekly Leaderboard Week 1: June 24th to June 27th Name Reviews Laura Fleig (GitHub Profile) 1 Ziyue (Tim) Liu (GitHub Profile) 0 Mahesh Bharadwaj (GitHub Profile) 0 Matthew David (GitHub Profile) 0 Siddhant Kumar (GitHub Profile) 0 Weekly Winner: Nobody since not everyone completed their PRs and nobody did 2 PRs\nWeek 2: July 1st to July 7th Name Reviews Mahesh Bharadwaj (GitHub Profile) 3 Matthew David (GitHub Profile) 1 Siddhant Kumar (GitHub Profile) 1 Laura Fleig (GitHub Profile) 0 Ziyue (Tim) Liu (GitHub Profile) 0 Weekly Winner: Nobody since not everyone completed their PRs\nWeek 3: July 8th to July 15th Name Reviews Mahesh Bharadwaj (GitHub Profile) 0 Matthew David (GitHub Profile) 1 Siddhant Kumar (GitHub Profile) 0 Laura Fleig (GitHub Profile) 1 Ziyue (Tim) Liu (GitHub Profile) 0 Sophia Yu (GitHub Profile) 0 Weekly Winner: Nobody since not everyone completed their PRs\nWeek 4: July 15th to July 22nd Name Reviews Laura Fleig (GitHub Profile) 1 Mahesh Bharadwaj (GitHub Profile) 0 Matthew David (GitHub Profile) 0 Siddhant Kumar (GitHub Profile) 0 Ziyue (Tim) Liu (GitHub Profile) 0 Sophia Yu (GitHub Profile) 0 Weekly Winner: Nobody since not everyone completed their PRs\nWeek 5: July 22nd to July 29th Name Reviews Laura Fleig (GitHub Profile) 1 Mahesh Bharadwaj (GitHub Profile) 0 Matthew David (GitHub Profile) 0 Siddhant Kumar (GitHub Profile) 0 Ziyue (Tim) Liu (GitHub Profile) 0 Sophia Yu (GitHub Profile) 0 Weekly Winner: Nobody since not everyone completed their PRs\nWeek 6: July 29th to August 5th Name Reviews Laura Fleig (GitHub Profile) 0 Mahesh Bharadwaj (GitHub Profile) 0 Matthew David (GitHub Profile) 0 Siddhant Kumar (GitHub Profile) 0 Ziyue (Tim) Liu (GitHub Profile) 0 Sophia Yu (GitHub Profile) 0 Weekly Winner: Nobody since not everyone completed their PRs\nMonthly Leaderboard June / July Name Total Reviews Laura Fleig (GitHub Profile) 4 Mahesh Bharadwaj (GitHub Profile) 3 Matthew David (GitHub Profile) 2 Siddhant Kumar (GitHub Profile) 1 Winner: Laura Fleig (GitHub Profile)\nCurrent Value: $50\nConclusion The contest ended.\nI am not sure code reviews improved much since I was busy with other matters than running the contest. It did increase communication in the team as people tried others pull request. I do believe it was a net positive and certainly worth more than money I paid out for it.\nMy hypothesis: It might be useful to teach people to write issues and review pull requests is better than teaching them how to code. In fact to any non-CS fresh graduates people out there, I hope I never have to see your code. It infuriates me to no extent.\n","permalink":"https://prudhvirajn.github.io/posts/code-review-contest/","summary":"Few more people did code review. I ended up trying to automate code review with Claude github action","title":"Code Review Contest"},{"content":"~ Encouraged by enlightening conversations with Prof Leon Bergen. All views are solely mine and do not reflect anyone else\u0026rsquo;s.\nBackground Generally, monetary betting is frowned upon and is illegal in India. It is seen as disrespectful to the Goddess of Wealth. However, I realized if I were to succeed as a researcher I need to learn how to identify research problems and argue initial hypothesis. As an engineer, I built my value function by simply using my tools and having others use my tools and give me feedback. Unlike for products, I believe there is a lot of noise in researcher\u0026rsquo;s value functions especially for a nascent field such as Machine Learning.\nProf Bergen and I often discussed hosting bets to gauge if our predictions were correct. As such this post will be an evolving post formatted as following:\nI will be making bets every 6 months Each bet will be written / rewritten over that week to allow me to finalize my predictions I will be making predictions on the following timescales: 6 months / 1 year / 5 years When a bets duration expires, I will evaluate if I was succesful at making a predictions Week 28th June 2024 to 5th July 2024 6 Month Bets Current Background: Working on educational apps thus my evaluation of models is biased by this work.\nBet 1: Claude 3.5 Opus will be the LLM frontier model I believe the best model for the next 6 months on most tasks would be the Claude 3.5 Opus model. There a few reasons for me to believe this:\nClaude 1 / Claude 2 was clearly behind the latest GPT models at time of release Claude 3 when released was one year behind GPT 4 models but was the only comparable model Claude 3.5 Sonnet is the first model to conclusively beat current OpenAI flagship models Claude 3.5 Opus \u0026gt; Claude 3.5 Sonnet The above stated progression makes me believe that OpenAI\u0026rsquo;s pace of developing frontier models has slowed down comparatively Google just released Gemini 1.5 Pro few months ago and Claude 3.5 Sonnet seems to be better I believe Google / OpenAI are increasingly focused on new ways of deployment and possible post-training of model As Meta\u0026rsquo;s Chameleon pointed out, training end-to-end multimodal models have additional challenges combined with my next point which I believe further slowed the pace of developing frontier models Given the instability at OpenAI, I believe OpenAI\u0026rsquo;s focus has shifted more to deployment of AI models rather than intensely focused on developing frontier capabilities This has happened before GPT2 came in 2019, GPT3 in 2020 but GPT4 came in 2023 (I believe OpenAI had a setback of a year due to figuring out Mixture-Of-Experts and researchers leaving to create Anthropic) Note: By frontier, I don\u0026rsquo;t necessarily mean best at public benchmarks. It\u0026rsquo;s quite possible that OpenAI / Google develop a new post-training / distillation methodology that boosts performance similar to how InstructGPT was better than GPT3 despite being 100x smaller. For ex, GPT-4o has better conversational abilities but it is worse at teaching (in my view) than GPT4-turbo or GPT-4 because it likely can\u0026rsquo;t compute higher order pedagogical reasoning.\nSo while, GPT-4o is arguably better to talk to and follows instructions better, it\u0026rsquo;s foundational frontier capabilities are not better than GPT-4.\nHere are the capabilities which I consider foundational:\nZero Shot Reasoner In Context Learner Long Context Reasoning Verifiability: If I am using the OpenAI API for developing most of my applications at the end of 6 month period then I would say I was wrong. Right now the rate is 100% OpenAI use. Unclear to me what benchmarks are there to evaluate ICL and Long Context reasoning as a frontier task.\nNote: I am unclear what is the frontier model for other modalities.\nBet 2: OpenAI will shift from ChatGPT product to an agent deployment OpenAI will showcase new post-training and/or scaffolding / \u0026ldquo;unhobling\u0026rdquo; in 6 months.\nWe have already seen OpenAI introduce the notion of memory in ChatGPT. It is clear they want to develop a desktop assistant agent app. However, assistant tasks are longer horizon than what current ChatGPT is capable of. In my view, its a post-training problem to figure out and maintain the right context to get the models to work. There is not enough long-horizon pre-training data. Furthermore, no matter how capable the model is at long-horizon, it will still need to develop scaffolding techniques to figure out memory. It is unlikely, that we deploy models where the context window contains all previous tokens for every small task we would want to do.\nFurthermore, this Fall would be 2 years since ChatGPT which arguably kick-started this revolution. It\u0026rsquo;s a good period to introduce the next big thing in my view.\nVerifiability: OpenAI releases a blog post talking about their new technique and we see the new desktop app in action\nBet 3: If LLAMA3-400B releases, there will be a end-to-end finetuned multimodal model If LLAMA3-400B releases, there will be a end-to-end finetuned multimodal (text/image guaranteed) possibly (text/image/audio) LLAMA3-400B.\nGPT4 was the first model that could use tools which is crucial for applications. LLAMA3-400B in my view would the first useful open-source model for end-user assistant application (someone who is not a prompt engineer) and I fundamentally believe that end-to-end multimodal is better way to interact for an application. For ex, how can someone ask for help when one is working on CAD design.\nVerifiability: If its open-source, then its easily verifiable. Difficult to verify if its close source. I can only confirm close-source if such an application exists and someone in the industry tells me they are using LLAMA3 without making me sign an NDA.\nBet 4: OpenAI would not release end-to-end multimodal freely on their API This means one can not just call the end-to-end model without prior permission from OpenAI. In my view, OpenAI would focus on enterprise customers that they can get longer-term usage agreements rather than individual developers. I believe this for the following reasons:\nRight now people can easily switch APIs every month or few months depending on whichever is the better model. This was fine when OpenAI reigned supreme. As I mentioned, I don\u0026rsquo;t believe that will be the case in the future and for most backend hidden use-cases smaller models and open-source models work fine. Reduces the risk of incorrect deployment of models causing harm to the OpenAI brand. Since OpenAI is the front for all AI now, anytime I see articles on how AI is bad, there is often an association of OpenAI. Thus, OpenAI would want to reduce this moving forward given how easily an end-to-end multimodal model can be misused. OpenAI would want to reduce competition for its desktop agent app which I believe has the potential to become the interface for the net upending Google (I don\u0026rsquo;t mean OpenAI develops a search engine just that it issues calls to a search engine and becomes the interface) Verifiability: Easily verifiable\nEnd Date: January 5th 2025\n1 Year Bets Current Background: Working on educational apps thus my evaluation of models is biased by this work.\nBet 1: GPT-5 generation frontier model will release or be announced GPT3 released in 2020, GPT4 in 2023, GPT5 level model should be announced or released in 2025 Anthropic will develop a GPT5 level model before OpenAI, but they might not announce it before OpenAI. Anthropic\u0026rsquo;s rate of progress of frontier model seems to be faster than OpenAI, this could be late comer\u0026rsquo;s advantage but I believe Anthropic has been making consistent research progress due to their lack of product diversity and researcher retention (as Dario Amodei put it, all founders are still at Anthropic) I truly believe Anthropic\u0026rsquo;s work in interpretability is important and improve our understanding of scaling which in turns allows faster scaling Mira Murati went record saying GPT5 will be a year and half later (putting the timeline for OpenAI around December 2025 which is around the 10 year anniversary of OpenAI) Deepmind\u0026rsquo;s Gemini Pro released in Dec 2023, Gemini 1.5 released in Feb 2024, it is highly likely Gemini 2 will release in Dec 2024. But I don\u0026rsquo;t believe Gemini 2 will be GPT5 level (apart from the context window length claims). I think Google wants to quickly release AI products to protect search and Deepmind wants to do research and there is conflict of interests in my view. This is why Gemini\u0026rsquo;s main selling point has been the context window length in my view. I will predict what I believe the model will be capable of by listing tasks it can do:\nWeb Research: Given a task, such as \u0026ldquo;write a report on underperforming stocks based on relevant metrics\u0026rdquo;, the model (only one model) would be able to figure out the relevant things to search, reason across the long context of its actions, compose a highly detailed document which includes figures and write a report. A standard report but relevant data needs to be identified and collected to write such automated reports.\nEducation: Solves all undergraduate level tutoring. Based on task 1, it is highly likely it can come up with lesson plans and deliver lectures. But would not be able to do so for new graduate topic classes that haven\u0026rsquo;t been taught. For example, any course at UCSD that is taught under the code CSE 291.\nSoftware Engineering: Get a score of greater than 80% on SWE-bench (Current highest is 19%)\nVerifiability: Easily Verifiable by announcements. The Anthropic claim is hard to verify if they don\u0026rsquo;t announce it. But I will count my claim to be true if their release comes within a month of OpenAI releasing GPT 5. For my prediction regarding tasks, I will need to look up / create a benchmark.\nBet 2: 2025 would mark the highest GenAI penetration in consumer products Basically the first app that people will use won\u0026rsquo;t be the browser.\nWhile all I can think about these days is Generative models, for most ordinary people don\u0026rsquo;t use or wouldn\u0026rsquo;t think to use ChatGPT on a daily basis. It\u0026rsquo;s probably something they heard in the news or a comedy sketch. GPT4\u0026rsquo;s tool use ability made the first model that can be directly somewhat useful to an ordinary human. GPT3 was useless. It is highly likely GPT5 level model + OpenAI\u0026rsquo;s desktop agent will change how everybody uses their computer. Microsoft + Apple have also released their own versions of how LLMs will be used. But I truly believe a GPT 5 level model and new scaffolding techniques are required to truly change how people interact with their computers. GPT5 level model requires rethinking how human workflows are carried out in companies, but that is harder in my view than giving people a chatbot subscription and asking them to use it. Thus, if a prediction of \u0026ldquo;impending recession\u0026rdquo; (in my view recessions / growth are always impending), then businesses would likely incorporate AI due to worker cuts. Verifiability: Easily verifiable\nBet 3: Some Data Distributions make language models easier to be mechanistically interpreted This is just my wish. A lot of people write how GPT can\u0026rsquo;t do this and that. Then they scoff at when people point to transformers trained on reasoning tasks (arguing that took too much data). I believe the following:\nLet task T be a relation between languages L_I and L_O where a language is a set of strings composed of elements of an alphabet If we have a verifier V such that V(y | x) is true if T(x) = y, then for any given input x from L_I, we can run V(y_i | x) on all y_i from L_O. However, this is an inefficient brute force algorithm. Here the complexity to generate an answer is equivalent to the number of strings * length of the string * complexity of verifying an individual string We can argue that a smarter algorithm would require to run the verifier on fewer strings If an algorithm can reason over a task, it will always generate only one string which is accepted by the verifier Assumption: Reasoners are easier to interpret than other algorithms since its the same algorithm for all instances For some tasks, the space spanned by transformers of a particular size contains reasoners During training, we eliminate some hypothesis based on empirical risk If we have a data distribution, then with sufficiently many samples, we could narrow down to hypothesis that reason (I wonder how the number of samples vary depending on the data distribution) It would be desirable to know the relationship between distributions of data and the abilities of models trained on them Note: It is unclear to me whether reasoning is simply pattern matching or not. After all one can say given a formal system of rules of resolution, one only need to identify the relevant rule for deduction. We can keep doing this until we can deduce all statements. If reasoning is pattern matching, then I think a model that reasons can be more easily interpreted.\nBy properties, I mean the properties are verifiable by mechanistic interpretability and not task performance.\nVerifiability: Easily verifiable if a paper exists. I would not surprised if there is such a paper exists. I know of there is an entire body of work of just mainpulating data to see its effect on models.\nJul 1st Undermind result:\nNo papers were found that empirically compare different preprocessing techniques and their impact on the interpretability of transformer-based language models.\nMost retrieved papers focus on the performance impact of preprocessing techniques on transformer models. For instance, one explores how different preprocessing steps influence BERT\u0026rsquo;s sensitivity and classification outcomes in detecting offensive language, but does not focus on interpretability. Papers delve into improving the interpretability of transformers using attention-based methods but do not compare preprocessing techniques. Comprehensive studies directly addressing the impact of preprocessing on both performance and interpretability of transformer-based models are needed for thorough empirical analysis.\nEnd Date: July 5th 2025\n5 Year Bets Bet 1: Smarter LLMs can be trained from data generated by dumber LLMs without leading to nonsensical outputs Basic Argument: Humans generated all their language based on observations from the world. Children learn from this language to gain world knowledge. AI can get observations from the world. Any AI that claims to be human level, must be able to learn from its own outputs.\nAssumption: On average newer generations are smarter than older generations. I would say economic output is an indicator?\nThe basic argument depends on the notion that AI have to be human level intelligent. We don\u0026rsquo;t require AI to be human level intelligent. If you refer above to my informal definition of a smartness, if AI comes close to human intelligence then we can expend more compute and still generate human quality outputs. We may not be human level efficient in generating this outputs.\nWe do not currently see this since the AI currently are too dumb and do not narrow the search space enough for us to find high quality generations. Furthermore, it could be that current models can not perform verifications for such human level tasks.\nBut in my view, GPT-6 level model (imagine two jumps in capability from GPT2 to GPT4) would get us close to human intelligence. I don\u0026rsquo;t think it will be an accepted AGI model. (Again I am fuzzy on the definition of AGI). Hence my prediction which I believe is easier to verify. This also signals that AIs can then re-produce themselves without the need for humans to generate any new knowledge.\nVerifiability: Easy to verify if we see academic results. Hard to know in industry.\nBet 2: We will observe another Chain Of Thought type phenomenon or an upgraded version of it What does a Chain of Thought type phenomenon mean?\nIt\u0026rsquo;s a phenomenon where models can bootstrap their performance without any outside influence except for a few tokens such as \u0026ldquo;Think step-by-step\u0026rdquo; or without any outside tokens.\nThey start writing / searching tools to solve problems without being prompted? The pre-trained models start writing plans / do chain of thought style reasoning to solve tasks without being prompted / trained to do so For a given task T, they can automatically identify relevant skills to learn and get examples of that? Something wilder? Verifiability: Easily verifiable since everybody will be doing this in their Benchmarks\nBet 3: We don\u0026rsquo;t need any RLHF RLHF in-short involves the following:\nCollecting user feedback on model responses Finetuning a classifier head on a pre-trained model to create a reward model to rate more responses Doing RL on the pre-trained model to increase the reward assigned by the reward model Why do we not need RLHF in the future?\nIf you believe that zero-shot and ICL are core model abilities that get better with scale. It stands to hold that a smarter pre-trained model can assign rewards to responses without the need for additional fine-tuning It is also possible that we don\u0026rsquo;t need to do RL on the pre-trained model rather simply give examples of good responses for it to generate good responses Constitutional AI demonstrates this in a limited manner to remove harmful responses Mechanistic interpretability improves to identify undesirable behaviour and we don\u0026rsquo;t need to rely to fine-tuning Bet 4: College becomes more expensive and fewer people attend college Verifiability: Easy\nBet 5: Median household incomes fall in US from 2022 levels (accounting for inflation) but credit interest rates fall to near 0 Verifiability: Easy\nEnd Date: July 5th 2029\nLast Updated: July 7th (as I forgot to do in week, this series of bets will not be updated)\n","permalink":"https://prudhvirajn.github.io/posts/bets-2024/","summary":"Bets for 6 months, 1 year and 5 year","title":"Bets 2024"},{"content":"The Tower I intended to write this post in February after my birthday. But three months have passed with me admitting defeat to jekyll, academicpages and other github blog templates. I can\u0026rsquo;t anymore with reinstalling packages everytime I want to update my blog on a new machine. But you are not here to read that. So how did I make it all these years?\nLevel 0 My first clear memory is from when I was around 5 years old. It was a warm afternoon. The sunlight dripped through the towering trees. A slow breeze choreographed the swaying of leaves. I remember staring at a small plant. The soft red soil. How it was so different than the hard concrete? Messy, dirty yet gentling holding me up. Out of it emerged ants marching onto an unknown destination. I always wondered how ants formed such straight lines. They never stop even with obstructions, determined to reach their goal. Yet what was mine I wonder? All I can remember is how I was amazed by my surroundings. By how everything seemed to work in harmony.\nLevel 1 Then I entered. School. Every year I was promised more than last. You sit on a desk and an adult walks in to teach you new concepts. Slowly the number of subjects multiplied. Science became physics, chemistry, biology, geology and ecology. Ok I lied on the last one, it was called environmental science, but that sounds cumbersome compared to ecology. But all you have to do is listen, read and you shall learn. At the end of a semester, you get graded. Higher the grades, the bigger the bragging rights. I will be fairly honest at this point. I have never been interested in grades unless they are 100%. Simply because 100% makes my mom happy anything else she just says good effort and why did you loose points.\nBut I was more interested in joining the dots every year. You learn an object falls with constant acceleration on year. The next you learn there is drag. Each time it was like rediscovering the world again in front of my very eyes. Decade and half later, I came across Feynman\u0026rsquo;s lectures on Physics where he says \u0026ldquo;philosophically we are completely wrong with the approximate law. Our entire picture of the world has to be altered\u0026rdquo;. I did not know about philosophy until many years later (For me philosophy at that point was religion and I had never cared for religion). But I had grown tired of memorizing falsehoods and why people insisted on quizzing me on laws I knew did not stand true. (I am looking at you IIT-JEE syllabus which forced me to memorize J.J Thompson\u0026rsquo;s plum-pudding model when I had already learnt Rutherford\u0026rsquo;s model in middle school. Also why would anyone want to memorize the atomic numbers for the first 30 elements in the periodic table)\nLevel 2 During my high school, I had the great privilege of travelling 30kms daily across Mumbai to attend my high school. I would start my journey staring at Antilla (the most expensive private residence barring Buckingham\u0026rsquo;s Palace), ride in a bus through one of the largest slums in Asia and make it to the middle-class Mumbai uncle\u0026rsquo;s paradise which I called home. While, I had always wondered why some people were born rich and others poor. It seemed to be a topic no one was delighted to talk about. One thing was clear to me that the Indian government was inept at best and an oppressor at worst.\nI took my chance to attend an American university. I wanted to see why America prided itself as the best in the world. Furthermore, I took up Computer Science because I could get a job anywhere in the world with a CS degree. I will be simply honest. I highly distrusted the Indian govt\u0026rsquo;s ability to allow Indian to develop. Thus, I thought it was imperative I secure skills that would allow me to find passage in a slightly more hopeful land. To sum it up, when I was leaving for America, an uncle told me, \u0026ldquo;Don\u0026rsquo;t come back even if your parents ask you to, find a better life elsewhere\u0026rdquo;. In all reality, I did think I could comeback to India and make a difference. While I did distrust the govt, I presumed it would change as people got better access to technology.\nHowever, for the first two years it seemed I made the wrong choice. My understanding of the world did not increase in anyway. While, I do enjoy programming and engineering as a hobby, I do not find it particularly meaningful. That is not to say I don\u0026rsquo;t find certain projects meaningful. But they are meaningful because of their aims rather than the means. For me engineering is the same as playing guitar or playing chess. Except it seems to make tens of thousands of dollars and no one pays me to hear me play guitar. I know I am a damn good engineer with values. If I do care about the aims of a project, it is hard for me to say no. This is a quality I regret. It seems to me that what makes many people great at scientific fields is simply because they suck at many other things. They have no choice but to do that one thing. There are exceptions but on the whole this seems to be as the general rule. (I am currently introspecting the place of values vs interests in making decisions)\nEven my programming skills weren\u0026rsquo;t particular improving. I couldn\u0026rsquo;t bring myself to devote tens of hours learning how to develop user applications which I absolutely hated. If it were up to me, all applications would be command line interfaces. (There is an argument to be made that text-based LLMs are just command line interfaces; In the next 5 years, I wonder if GUIs stick around, I hope not I hate programming them) It wasn\u0026rsquo;t until Discrete Structures that hope returned to my life. I learnt about proofs for the first time. The notion that there exists a universal system to establish the truth of a statement was a life changing event for me. But I soon stumbled on a problem. How do I know time (in general casualty) exists? This was a devastating blow for me that would take a few more years to recoup from. This eventually led me to accepting that one needs beliefs (not the religious kind) and cannot solely rely on truths.\nDuring this time (see what I did there), I somehow learnt machine learning to make ends meet in industry. Don\u0026rsquo;t ask me how, it was a rough year and a half at a small startup (Somehow my luck seems to be tied with startups). I viewed it and still view it as a natural phenomenon. How does one learn a computational algorithm to decide the difference between oranges and mandarins?\nLevel 3 After undergrad, I started a masters program to learn more about this phenomenon and along the way acquired some more skills (I won\u0026rsquo;t bore you any further). Let me just say, I am extremely happy to be in warmer San Diego rather than freezing Cincinnati. Albeit these days the weather in San Diego seems gloomy. The phenomenon of learning in my view is the most important phenomenon to study. By learning I am referring to known computational algorithms, I am only interested in how humans learn so far as to it\u0026rsquo;s the an efficient learning algorithm known (I have my doubts, I need to crunch some numbers). The reason I am slightly skeptical is because while its true humans seem to require fewer examples to learn. We also consume 16 hours of interactive data every day followed by 8 hours of sleep (no clue what happens there). Furthermore, if one looks at the economic value of a human being, it only starts to exponentially increase after 10th grade. That means it takes for a human about 14 years to be as economic valuable as a cashier compared to a few months to a LLM (There are kids in India who sell stuff but there age would probably no less than 8). It might be true that the human uses less energy in a decade. But, I would have to crunch the numbers.\nBut to define precisely, let\u0026rsquo;s loosely define a learner to be a sequence of finite steps that takes in a series of observations (x,y) from a unknown distribution produces a model to accurately predict y given x. Right the most important and interesting question to me is how to quantify the efficiencies of current learning processes and generate explanations for why some learners are more efficient than others. In a way, I need to be a learner about learners. Alright, I will stop with the sad jokes.\nLeaving the Tower Unlike school, there are no levels to climb in this mission. I know when I take concrete steps but I probably won\u0026rsquo;t know about incorrect steps after some weeks or months. In some ways, I am the ant I so often saw during my childhood. I do not know if this the right thing to do but it feels like it is. I do not know where I or the world will be in 5 years. But I do not think I will regret it. I do plan on tackling this problem with my full might when my PhD starts. There is currently an important project before I do. I am currently working on educational tools powered with AI for undergraduate courses. College education in my view has been in decline for the past few decades. I believe we can reverse or at the very least prevent further decline of this trend.\nIn review, I never thought I would live till 25. I do not know if I will see the next 25. I can not imagine how people live till 75. That just seems insane to me. I wanted to write this post with more structure and on diverse topics. But it ended being me rambling. I will write about the other topics in their own posts. But here is a list so you can bug me if I don\u0026rsquo;t end up writing:\nWhat worries me most about AI: Feudalism What I think I will need to do to prepare for the next 25 India @ 2047 America @ 2077 Are Humans efficient learners? Few other random bets about the future ","permalink":"https://prudhvirajn.github.io/posts/turning-25/","summary":"Reflections on my life till turning 25.","title":"Turning 25"},{"content":"Background When I was about 10 years old, my dad bought a WiFi router. It was the most amazing thing I had seen at the time. A little of bit of context. The packets of Internet used to pilgrimage through the telephone line before being rendered on the dusty CRT monitor desktop. To ensure safe passage, upon starting the computer, one used an application on the computer to setup a dial-up connection to the ISP. If god forbids, one of my relatives decided to call unannounced, I would loose my internet connection when my mother decided to answer the phone. At that time you see, call packets (and my mother\u0026rsquo;s conversations with distant relatives) were given preference to my humble internet packets (my net surfing time). One day he brought in the router, which safe-guarded my internet connection against my mother\u0026rsquo;s tyrannical conversations. The router also had a wireless connection option. The idea that packets of information could float through the air carrying videos blew my mind away. I could sit in peace undistrubted by the tyranny of the telephone.\nBut this is my earliest memory of being astounded by technology. I possibly had been amazed before, but I can\u0026rsquo;t recall those memories. Amongst all the technological advancements since then, my experience with ChatGPT triumphs my earliest memory of marvelling at technology. Inspite of claims such as ChatGPT is dumber than a dog1, the point is who cares? Since the existence of humans, has a human being ever been able to carry out a conversation with any non-human? I have used ChatGPT as a programming assistant, I simply ask for code and often just copy-paste the outputs. The recent advancements where ChatGPT can now see, hear, and speak2 make this even more remarkable. It is able to discern possible causes and offers debugging strategies. In practice, does it really matter if it actually \u0026ldquo;reasoned\u0026rdquo; or was able to compress enough human knowledge from the internet and customize a likely strategy. I am saddened to say it is better at debugging code (written by it or someone else) than the undergraduates / graduates I have worked with at UCSD. I will grant that the jury may be still out on whether it can\nReferences Artificial intelligence is not yet as smart as a dog, Meta A.I. chief says Link\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nChatGPT can now see, hear, and speak Link\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","permalink":"https://prudhvirajn.github.io/posts/chatgpt-aint-it/","summary":"Reflections on the marvel of ChatGPT technology and its impact on programming and debugging.","title":"ChatGPT Ain't It"},{"content":"Prudhviraj Naidu PhD Student in Computer Science\nEmail: your.email@domain.com\nGitHub: github.com/prudhvirajn\nWebsite: prudhvirajn.github.io\nEducation PhD in Computer Science (Expected: Year)\nUniversity Name\nDissertation: [Your dissertation title]\nAdvisor: [Advisor Name]\n[Previous Degree] (Year)\nUniversity Name\nGPA: X.X/4.0\nResearch Interests Machine Learning: Deep learning, neural network testing, metamorphic testing Software Engineering: Software testing methodologies, quality assurance Information Retrieval: Scientific document retrieval, multi-level aspect-based queries Publications Journal Articles 2022\nHemanth Gudaparthi, Prudhviraj Naidu, and Nan Niu. \u0026ldquo;Metamorphic Testing of Image Classification and Consistency Analysis Using Clustering.\u0026rdquo; International Journal of Multimedia Data Engineering and Management (IJMDEM), vol.13, no.1, 2022, pp.1-20.\nConference Papers 2023\nJianyou Wang, Kaicheng Wang, Xiaoyue Wang, Prudhviraj Naidu, Leon Bergen, Ramamohan Paturi. \u0026ldquo;Scientific Document Retrieval using Multi-level Aspect-based Queries.\u0026rdquo; Thirty-seventh Conference on Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track, 2023.\n2021\nPrudhviraj Naidu, Hemanth Gudaparthi, and Nan Niu. \u0026ldquo;Metamorphic Testing for Convolutional Neural Networks: Relations over Image Classification.\u0026rdquo; 2021 IEEE 22nd International Conference on Information Reuse and Integration for Data Science (IRI), 2021, pp.99-106.\nExperience Graduate Research Assistant (Year - Present)\nUniversity Name\nResearch on metamorphic testing for machine learning systems Developed novel approaches for neural network validation Collaborated on scientific document retrieval systems [Previous Experience] (Years)\nOrganization Name\nDescription of responsibilities and achievements Skills Programming Languages: Python, Java, C++, R, JavaScript\nMachine Learning: TensorFlow, PyTorch, scikit-learn, Keras\nTools \u0026amp; Technologies: Git, Docker, Linux/Unix, LaTeX\nDatabases: SQL, MongoDB, PostgreSQL\nAwards \u0026amp; Honors [Award Name] (Year) [Honor/Recognition] (Year) Service Reviewer\n[Conference/Journal Name] (Year) Teaching Assistant\n[Course Name] (Semester Year) Selected Coursework Advanced Machine Learning Software Engineering Principles Data Mining and Knowledge Discovery Statistical Methods in Computer Science Download PDF version: CV.pdf\nLast updated: [Current Date]\n","permalink":"https://prudhvirajn.github.io/cv/","summary":"\u003ch1 id=\"prudhviraj-naidu\"\u003ePrudhviraj Naidu\u003c/h1\u003e\n\u003cp\u003e\u003cstrong\u003ePhD Student in Computer Science\u003c/strong\u003e\u003cbr\u003e\nEmail: \u003ca href=\"mailto:your.email@domain.com\"\u003eyour.email@domain.com\u003c/a\u003e\u003cbr\u003e\nGitHub: \u003ca href=\"https://github.com/prudhvirajn\"\u003egithub.com/prudhvirajn\u003c/a\u003e\u003cbr\u003e\nWebsite: \u003ca href=\"https://prudhvirajn.github.io\"\u003eprudhvirajn.github.io\u003c/a\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"education\"\u003eEducation\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003ePhD in Computer Science\u003c/strong\u003e \u003cem\u003e(Expected: Year)\u003c/em\u003e\u003cbr\u003e\nUniversity Name\u003cbr\u003e\n\u003cem\u003eDissertation: [Your dissertation title]\u003c/em\u003e\u003cbr\u003e\n\u003cem\u003eAdvisor: [Advisor Name]\u003c/em\u003e\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003e[Previous Degree]\u003c/strong\u003e \u003cem\u003e(Year)\u003c/em\u003e\u003cbr\u003e\nUniversity Name\u003cbr\u003e\n\u003cem\u003eGPA: X.X/4.0\u003c/em\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch2 id=\"research-interests\"\u003eResearch Interests\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eMachine Learning\u003c/strong\u003e: Deep learning, neural network testing, metamorphic testing\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eSoftware Engineering\u003c/strong\u003e: Software testing methodologies, quality assurance\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eInformation Retrieval\u003c/strong\u003e: Scientific document retrieval, multi-level aspect-based queries\u003c/li\u003e\n\u003c/ul\u003e\n\u003chr\u003e\n\u003ch2 id=\"publications\"\u003ePublications\u003c/h2\u003e\n\u003ch3 id=\"journal-articles\"\u003eJournal Articles\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003e2022\u003c/strong\u003e\u003cbr\u003e\nHemanth Gudaparthi, \u003cstrong\u003ePrudhviraj Naidu\u003c/strong\u003e, and Nan Niu. \u0026ldquo;Metamorphic Testing of Image Classification and Consistency Analysis Using Clustering.\u0026rdquo; \u003cem\u003eInternational Journal of Multimedia Data Engineering and Management (IJMDEM)\u003c/em\u003e, vol.13, no.1, 2022, pp.1-20.\u003c/p\u003e","title":"Curriculum Vitae (Don't Look, Work In Progress)"},{"content":"Journal Publications 2022 Hemanth Gudaparthi, Prudhviraj Naidu, and Nan Niu\n\u0026ldquo;Metamorphic Testing of Image Classification and Consistency Analysis Using Clustering\u0026rdquo;\nInternational Journal of Multimedia Data Engineering and Management (IJMDEM), vol.13, no.1, 2022, pp.1-20\n[Paper]\nConference Publications 2023 Jianyou Wang, Kaicheng Wang, Xiaoyue Wang, Prudhviraj Naidu, Leon Bergen, Ramamohan Paturi\n\u0026ldquo;Scientific Document Retrieval using Multi-level Aspect-based Queries\u0026rdquo;\nThirty-seventh Conference on Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track, 2023\n2021 Prudhviraj Naidu, Hemanth Gudaparthi, and Nan Niu\n\u0026ldquo;Metamorphic Testing for Convolutional Neural Networks: Relations over Image Classification\u0026rdquo;\n2021 IEEE 22nd International Conference on Information Reuse and Integration for Data Science (IRI), 2021, pp.99-106\n[DOI]\nFor the most up-to-date list of publications, please see my Google Scholar profile or ORCID.\n","permalink":"https://prudhvirajn.github.io/publications/","summary":"\u003ch2 id=\"journal-publications\"\u003eJournal Publications\u003c/h2\u003e\n\u003ch3 id=\"2022\"\u003e2022\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eHemanth Gudaparthi, Prudhviraj Naidu, and Nan Niu\u003c/strong\u003e\u003cbr\u003e\n\u003cem\u003e\u0026ldquo;Metamorphic Testing of Image Classification and Consistency Analysis Using Clustering\u0026rdquo;\u003c/em\u003e\u003cbr\u003e\n\u003cstrong\u003eInternational Journal of Multimedia Data Engineering and Management (IJMDEM)\u003c/strong\u003e, vol.13, no.1, 2022, pp.1-20\u003cbr\u003e\n\u003ca href=\"http://doi.org/10.4018/IJMDEM.304390\"\u003e[Paper]\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"conference-publications\"\u003eConference Publications\u003c/h2\u003e\n\u003ch3 id=\"2023\"\u003e2023\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003eJianyou Wang, Kaicheng Wang, Xiaoyue Wang, Prudhviraj Naidu, Leon Bergen, Ramamohan Paturi\u003c/strong\u003e\u003cbr\u003e\n\u003cem\u003e\u0026ldquo;Scientific Document Retrieval using Multi-level Aspect-based Queries\u0026rdquo;\u003c/em\u003e\u003cbr\u003e\n\u003cstrong\u003eThirty-seventh Conference on Neural Information Processing Systems (NeurIPS) Datasets and Benchmarks Track\u003c/strong\u003e, 2023\u003c/p\u003e\n\u003ch3 id=\"2021\"\u003e2021\u003c/h3\u003e\n\u003cp\u003e\u003cstrong\u003ePrudhviraj Naidu, Hemanth Gudaparthi, and Nan Niu\u003c/strong\u003e\u003cbr\u003e\n\u003cem\u003e\u0026ldquo;Metamorphic Testing for Convolutional Neural Networks: Relations over Image Classification\u0026rdquo;\u003c/em\u003e\u003cbr\u003e\n\u003cstrong\u003e2021 IEEE 22nd International Conference on Information Reuse and Integration for Data Science (IRI)\u003c/strong\u003e, 2021, pp.99-106\u003cbr\u003e\n\u003ca href=\"https://doi.org/10.1109/IRI51335.2021.00020\"\u003e[DOI]\u003c/a\u003e\u003c/p\u003e","title":"Publications"},{"content":"For centuries, people have argued how to produce, distribute and allocate resources to ensure a better society for all. But to get to what a state should be, I ask “What is a State?”\nIs a state a group of people sharing an identity? Is a state boundaries on a map? Is a state, a god’s authority on Earth? It might be not be easy to define a state in these terms. Different cultures, different beliefs, different societies and realities would make it difficult for me to conclusively state every possible version of a state in such manners. Therefore, I will look at a state from the perspective of security, economy and society. Allow me to further define these in terms what would it mean for a state.\nSecurity: The ability to protect the economy and society against external and internal threats. Economy: The net wealth in a state related to goods, services \u0026amp; resources and trade occurring in and out of the state. Society: A collection of entities capable of forming social relations amongst themselves, where social relation is defined as the ability to communicate information.\nI know that these definitions are loose. I will expand on these definitions in future articles. But for now, they are loose definitions for a reason. I will demonstrate below.\nConsider a forest from the perspective of security. How does a forest have security? Well a forest is often occupied by territorial animals. These animals guard their own regions of the forest and by additive value the forest at large. Or consider this, any threat to a forest will displace animals likely to disturb the very same entity displacing them. I know this isn’t the perfect security, but that’s beside the point. Consider a forest from the perspective of the economy. Surely animals don’t have material wealth or trade. Well animals do tend to store food. Squirrels with nuts and bees with honey. Furthermore, animals also tend to have symbiotic relationships such as birds eating food from crocodile’s teeth. It is hard or next to impossible for me to ascertain monetary value of such things. But nonetheless, there does exist an exchange of goods in lieu of services such as in the case of birds and crocodiles. Or the forest with its abundant food and water supplies are also a wealth of their own. I am not considering wealth from minerals and other resources since I doubt these hold any value to animals. This is also a point I will discuss in future articles, but for now just from perspective of animals living in the forest.\nConsider a forest in terms of a society. Putting aside social animals, there is a certain degree of communication that occurs among animals. Simply growling is a communication that can occur between a tiger and a monkey. Where neither the tiger nor the monkey would traditionally be considered to be in a social group. But nonetheless some amount of communication can occur between different animals. Plants can put out fragrances to attract animals. Naturally there may be instances that two entities in a forest may not be able to directly or indirectly communicate and we can argue if a forest should be considered to be made up of multiple states. But I am not really an zoologist to dive into such matters. Those discussions do lie out my realm of understanding.\nBut let us look at one such entity, the beehive. Anybody can attest to the security of a beehive. If not, feel free to go poke a beehive. Then let me know your experience. The wealth of a beehive can simply be measured in the amount of honey it has. Furthermore, you can consider the beehive “state” to trade with flowers by performing services of carrying pollen in exchange of nectar. Lastly, the societal aspect of a beehive. Bees tend to have a strict hierarchy where they are born in different classes such as worker, drone and queen to the best of our knowledge. These classes perform different functions for the state. The queen produces offspring, the drone bees mate, and the worker bees do a range of tasks from security to collecting nectar for the beehive. If this societal model doesn’t remind you of anything, I would like to point out examples of class systems across all civilizations in human history. Where people were born into professions, interacted primarily with people of the same class, lived and died in a class.\nBefore I continue, I hope the reader would permit me to take some space to make myself clear. I am not arguing that class system is the ideal society. I am just pointing out similarities between human states and states of other animals just to drive the notion that the Perfect State is simply a constructed notion based on need of production, administration and management of resources.\nMoreover, I can tell that some people will read this and go that the rigid class system is a natural way of life. Hence, society should be divided in classes. Firstly, the class system is a way of life. Just because bees and humans have do it, doesn’t mean it’s the only and ideal way of life. There are also many different types of class systems, there is rigidity of classes, inequalities among classes, and the list goes on. Secondly, even if you consider something to be a natural way of life. Then it makes no sense to actively or passively enforce it. Because that would be contradictory to the notion of it being natural.\nI will demonstrate with an example, let’s say you put forth the statement, “It is natural for any man to be with a woman and produce children and have a family”. Then it makes no sense for you to enforce that men need to be with women and produce children. Since according to the statement, it is supposed to be natural. If you need to enforce this notion on men who would not want to be with women or want to have children, then the statement is false since it is clearly not natural if you have to enforce it.\nI will give another example. Let’s say you put forth the statement, “Societies are naturally divided along the lines of people’s height. Hence short people and tall people need to be separated”. The same notion from the previous paragraph applies, if societies are naturally divided, you do not need to divide or separate them. If you have enforce a separation or division, then it is not natural.\nThis is why I don’t consider human/animal rights to be a natural thing. Since, it has to be enforced by a state. This is also a demonstration that just because something is unnatural doesn’t mean it’s bad. Since, people do seem to be in agreement that rights are a good thing. Whether it is natural for states to decide and enforce rights, is whole another matter. I will explore it when I write the article related to rights.\nSo a beehive seems to resemble more of what we would consider a state than a forest. Beehives have an hierarchy, a clear storage of food, coordinated actions taken against enemies, and in general it is less chaotic than forests. Despite, the fact that both the beehive and the forest exhibit the notions of security, economy and society. The key difference between both these systems is communication channels. For example, consider when a forest in under attack. A tiger protecting one area of the forest can’t really coordinate with a leopard protecting another area. Communication between animals and plants of different species may be limited to acts of aggression such as growling or throwing objects or running away.\nOn the other hand, consider communication between bees. Bees can communicate sources of nectar with other bees, communicate threats against the colony. There is a more standard form communication amongst bees that allows them to effectively communicate more complex ideas than animals in forests. For example, a tiger may be limited to the amount of information it can communicate with the monkey in forms of growls or running away. Moreover, the information is not necessarily clear as to who the tiger is growling at, or why it is necessarily running away.\nBut nonetheless, it is certainly beneficial for societies to standardize communication channels for effective transmission of information. It is this need for standardization of communication channels that gives rise of governments. Governments are at the very least simply standardized communication channels for information to be conveyed in and out of a state.\nConsider currency, currency is a standardized form of exchange in an economy. It clearly conveys the value of the item, moreover is easy to transmit, usually concise and easily accessible in terms of exchanging it for other goods and services. Furthermore, it’s a guaranteed method of communication given by the government.\nOr perhaps consider judicial systems. Judicial systems are a standardized format of settling disputes. The judge doesn’t pass judgements acting on his own will, rather simply passes information relating to compensation or punishment which the state (depending on nature of the state, the society or part of it) has deemed in respect to the dispute. Even if the state grants a judge powers to settle disputes by his own notion. There still exists a selection process of a judge, thus the state is simply ensuring that certain information gets passed down when a dispute arises. The notions of communication applies to the government, however bizarre it may seem. While, it judicial systems are associated with notions of justice and righteousness. They still are communication channels, they can be judged on the basis of accessibility, clarity of information received and given out, how quickly they can give judgements, how much information is required to settle disputes, etc. I will talk more when I write about these specific topics.\nSo, what is a state. Rather than answering that question, I will say that the state that I am going to write about is a state occupying physical space, constituted of beings capable of communicating through communication channels often standardized and commonly referred to as governments.\n","permalink":"https://prudhvirajn.github.io/posts/the-perfect-state-what-is-a-state/","summary":"Exploring the fundamental question of what constitutes a state through security, economy, and society perspectives.","title":"The Perfect State (What is a State)"},{"content":"Before I delve into my ideas for a perfect state. I would like to introduce these series of articles, which I hopefully can complete to write out my thoughts on administration of a modern state.\nI write this at 9:15 pm 5th June 2020. The world has been through a pandemic, devastating lives and livelihoods across the worlds. Protests have erupted in the United States over a sad death of an African American. The Chinese released new declarations extending their security laws to Hong Kong. The Indians are hoping to come out of this pandemic, while staring at the end at an uncertain economic future. The Russians, where surprisingly coronavirus cases have spread rapidly, rolled out a coordinated surveillance system in Moscow under the pretense of combating the virus.\nAnd I happened to watch an interesting video by Marques Brownlee. He talked about his experience of staying silent about the treatment of African Americans. I wondered, maybe I should put my thoughts into the world. For what they are worth. I am not a political scientist.\nI am a student of Computer Science. I create frameworks, communication channels, create systems which manage resources and information. These frameworks have to be secure, robust, prone to logical fallacies. If this sounds similar, this is exactly what an administration does. I simply want to explore, what is administration, why an administration, what should an administration hope to achieve.\nI am not delving into politics. These articles are not about how one comes into power, but rather how should a state function irrespective of people constituting the state.\nPerhaps, these articles may not be read by anyone. I will still be satisfied, knowing there are out there in the world.\n","permalink":"https://prudhvirajn.github.io/posts/perfect-state-introduction/","summary":"Introduction to a series of articles exploring ideas for a perfect state and modern administration.","title":"The Perfect State (Introduction)"},{"content":"The first post, on what is hopefully a permanent personal site.\nWho am I?\nJust a wanderer across times.\n","permalink":"https://prudhvirajn.github.io/posts/first-post/","summary":"The first post on my personal website - a brief introduction.","title":"First Post"}]